{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# **Import the Relevant Packages**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow_datasets","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting tensorflow_datasets\n  Downloading tensorflow_datasets-2.1.0-py3-none-any.whl (3.1 MB)\n\u001b[K     |████████████████████████████████| 3.1 MB 4.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (0.18.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (1.18.1)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (1.11.2)\nCollecting tensorflow-metadata\n  Downloading tensorflow_metadata-0.21.1-py2.py3-none-any.whl (31 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (4.42.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (1.14.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (0.3.1.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (2.22.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (0.9.0)\nRequirement already satisfied: promise in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (2.3)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (1.1.0)\nRequirement already satisfied: attrs>=18.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (19.3.0)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets) (3.11.3)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.6/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.51.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow_datasets) (45.2.0.post20200210)\nInstalling collected packages: tensorflow-metadata, tensorflow-datasets\nSuccessfully installed tensorflow-datasets-2.1.0 tensorflow-metadata-0.21.1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\nimport tensorflow_datasets as tfds","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_dataset, mnist_info = tfds.load(name = 'mnist',  with_info = True, as_supervised = True)","execution_count":4,"outputs":[{"output_type":"stream","text":"\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /root/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b924062c2614ca1a7838e14bdce9128"}},"metadata":{}},{"output_type":"stream","text":"\n\n\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## **Preprocessing the Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_train, mnist_test = mnist_dataset['train'],mnist_dataset['test']\n\n# Fetching number of 10% of Train data for Validation dataset as TensorFlow Datrasets do not provide a readymade validation Sample \nnum_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\nnum_validation_samples = tf.cast(num_validation_samples, tf.int64)\n\n# Assigning new variable for test dataset\nnum_test_samples = mnist_info.splits['test'].num_examples\nnum_test_samples= tf.cast(num_test_samples, tf.int64)\n\n#Function Scaling the training and Validation data\ndef scale(image, label):\n    image = tf.cast(image, tf.float32)\n    image /= 255. #This is where the image value is scaled\n    \n    return image,label\n\nscaled_train_and_validation_data = mnist_train.map(scale)\n\ntest_data = mnist_test.map(scale)\n\n#Shuffling the Train and Validation Dataset\n\nBUFFER_SIZE = 10000\nshuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n\nvalidation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n\ntrain_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n\n#Preprocessing data for Batching and Batching\n\nBATCH_SIZE = 100\n\ntrain_data = train_data.batch(BATCH_SIZE)\nvalidation_data = validation_data.batch(num_validation_samples)\ntest_data = test_data.batch(num_test_samples)\n\n#TO give Validation data same SHAPE and PROPERTIES as train data and test data\nvalidation_inputs, validation_targets = next(iter(validation_data))","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = 784\noutput_size = 10\nhidden_layer_size =  200\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape = (28,28,1)),\n    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu' ),\n    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n    tf.keras.layers.Dense(output_size, activation = 'softmax')\n    \n])","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Selecting the Optimizer and Loss Function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Training the Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_EPOCHS = 10\n\nmodel.fit(train_data, epochs = NUM_EPOCHS, validation_data = (validation_inputs, validation_targets),validation_steps = 1, verbose = 2)","execution_count":11,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n540/540 - 15s - loss: 0.2705 - accuracy: 0.9214 - val_loss: 0.1087 - val_accuracy: 0.9687\nEpoch 2/10\n540/540 - 16s - loss: 0.1070 - accuracy: 0.9675 - val_loss: 0.0801 - val_accuracy: 0.9750\nEpoch 3/10\n540/540 - 15s - loss: 0.0712 - accuracy: 0.9785 - val_loss: 0.0606 - val_accuracy: 0.9823\nEpoch 4/10\n540/540 - 15s - loss: 0.0513 - accuracy: 0.9845 - val_loss: 0.0422 - val_accuracy: 0.9882\nEpoch 5/10\n540/540 - 15s - loss: 0.0381 - accuracy: 0.9880 - val_loss: 0.0412 - val_accuracy: 0.9870\nEpoch 6/10\n540/540 - 16s - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.0405 - val_accuracy: 0.9885\nEpoch 7/10\n540/540 - 15s - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0283 - val_accuracy: 0.9905\nEpoch 8/10\n540/540 - 15s - loss: 0.0231 - accuracy: 0.9920 - val_loss: 0.0241 - val_accuracy: 0.9933\nEpoch 9/10\n540/540 - 15s - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0237 - val_accuracy: 0.9927\nEpoch 10/10\n540/540 - 16s - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0172 - val_accuracy: 0.9942\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f32e0432128>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# **Testing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_data)","execution_count":15,"outputs":[{"output_type":"stream","text":"      1/Unknown - 2s 2s/step - loss: 0.0746 - accuracy: 0.9805","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( 'Test Accuracy is ', repr(test_accuracy *100), '% and Test Loss = ', repr(test_loss))","execution_count":21,"outputs":[{"output_type":"stream","text":"Test Accuracy is  98.04999828338623 % and Test Loss =  0.07456833124160767\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}